{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({8: 37, 7: 26, 6: 12, 0: 11, 1: 9, 5: 8, 2: 7, 3: 6, 4: 5})\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/datasets/Pain-study\"\n",
    "\n",
    "# read labels\n",
    "with open(os.path.join(data_dir, 'labels.txt'), mode='r', encoding='utf-8') as label_file:\n",
    "    labels = list(map(lambda x: int(x.strip()), label_file.readlines()))\n",
    "\n",
    "frequency = Counter(labels)\n",
    "print(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00        12\n",
      "           7       0.00      0.00      0.00        26\n",
      "           8       0.31      1.00      0.47        37\n",
      "\n",
      "    accuracy                           0.31       121\n",
      "   macro avg       0.03      0.11      0.05       121\n",
      "weighted avg       0.09      0.31      0.14       121\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzhaozhe/miniconda3/envs/xclass/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/zzhaozhe/miniconda3/envs/xclass/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/zzhaozhe/miniconda3/envs/xclass/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# most frequent\n",
    "# Get the most frequent class\n",
    "most_frequent_class = frequency.most_common(1)[0][0]\n",
    "\n",
    "# Create a constant prediction using the most frequent class\n",
    "constant_predictions = [most_frequent_class] * len(labels)\n",
    "print(classification_report(labels, constant_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.09      0.09        11\n",
      "           1       0.25      0.33      0.29         9\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.07      0.20      0.11         5\n",
      "           5       0.12      0.12      0.12         8\n",
      "           6       0.11      0.17      0.13        12\n",
      "           7       0.24      0.15      0.19        26\n",
      "           8       0.31      0.11      0.16        37\n",
      "\n",
      "    accuracy                           0.13       121\n",
      "   macro avg       0.13      0.13      0.12       121\n",
      "weighted avg       0.19      0.13      0.14       121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# uniformly random\n",
    "import numpy as np\n",
    "\n",
    "# Get unique labels from the original list\n",
    "unique_labels = list(set(labels))\n",
    "\n",
    "# Generate uniformly random predictions\n",
    "np.random.seed(42)  # For reproducibility\n",
    "uniform_random_predictions = np.random.choice(unique_labels, size=len(labels))\n",
    "print(classification_report(labels, uniform_random_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.09      0.10        11\n",
      "           1       0.11      0.11      0.11         9\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.11      0.12      0.12         8\n",
      "           6       0.08      0.08      0.08        12\n",
      "           7       0.15      0.19      0.17        26\n",
      "           8       0.26      0.22      0.24        37\n",
      "\n",
      "    accuracy                           0.14       121\n",
      "   macro avg       0.09      0.09      0.09       121\n",
      "weighted avg       0.14      0.14      0.14       121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stratify\n",
    "unique_labels = list(frequency.keys())\n",
    "probabilities = [freq / len(labels) for freq in frequency.values()]\n",
    "\n",
    "# Randomly sample labels based on the distribution of probabilities\n",
    "np.random.seed(42)  # For reproducibility\n",
    "distribution_based_predictions = np.random.choice(unique_labels, size=len(labels), p=probabilities)\n",
    "print(classification_report(labels, distribution_based_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
